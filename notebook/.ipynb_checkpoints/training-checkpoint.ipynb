{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4e5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfb1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None, name='Convolutional Encoder'):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.id = 'encoder'\n",
    "        \n",
    "        if output_size==None:\n",
    "            output_size=input_size\n",
    "            \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_size,hidden_size, 3, padding=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            \n",
    "            nn.Conv2d(hidden_size,hidden_size, 3, padding=(1,1), stride=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "                                \n",
    "            nn.Conv2d(hidden_size,output_size, 3, padding=(1,1), stride=(2,2)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.encoder(input) \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None, name='Convolutional Decoder'):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.id = 'decoder'\n",
    "        \n",
    "        if output_size==None:\n",
    "            output_size=input_size       \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(input_size,hidden_size, 3, padding=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            \n",
    "            nn.Conv2d(hidden_size,hidden_size, 3, padding=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            \n",
    "            nn.Conv2d(hidden_size,output_size, 3, padding=(1,1)),\n",
    "            nn.Sigmoid()        \n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.decoder(input) \n",
    " \n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module, name='Time Distributed'):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        \n",
    "    def forward(self, input):\n",
    "        batch_or_time1, batch_or_time2 = input.size(0), input.size(1)\n",
    "        \n",
    "        new_shape = list([batch_or_time1*batch_or_time2]) + list(input.shape[2:])\n",
    "        input = self.module(input.reshape(new_shape))\n",
    "        \n",
    "        output_shape = list([batch_or_time1, batch_or_time2]) + list(input.shape[1:])\n",
    "        return input.reshape(output_shape)  \n",
    "\n",
    "class CLSTM_cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, kernel_size=(3,3), padding=(1,1), name='CLSTM-Cell'):\n",
    "        \n",
    "        super(CLSTM_cell, self).__init__()      \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.conv = nn.Conv2d(input_size + hidden_size, hidden_size*4, kernel_size, 1, padding)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, input, H=None, C=None):\n",
    "        self.check_forward_input(input)\n",
    "        if H is None:\n",
    "            H = torch.zeros(input.size(0), self.hidden_size, input.size(2), input.size(3),\n",
    "                             dtype=input.dtype, device=input.device)\n",
    "        if C is None:\n",
    "            C = torch.zeros(input.size(0), self.hidden_size, input.size(2), input.size(3),\n",
    "                             dtype=input.dtype, device=input.device)  \n",
    "\n",
    "        conv_out = self.conv(torch.cat([input,H], dim=1)) # concatenate the features, [b, f_X+f_h, :, :] # [b, f_h,:,:]\n",
    "        _f, _i, _c, _o = torch.split(conv_out, self.hidden_size, dim=1)\n",
    "        \n",
    "        f = torch.sigmoid(_f)\n",
    "        i = torch.sigmoid(_i)\n",
    "        c = torch.sigmoid(_c)\n",
    "        o = torch.tanh(_o)\n",
    "        \n",
    "        C = C * f + i * c\n",
    "        H = o * torch.tanh(c)\n",
    "        return H, C\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def check_forward_input(self, input: Tensor) -> None:\n",
    "        if input.size(1) != self.input_size:\n",
    "            raise RuntimeError(\n",
    "                \"input has inconsistent input_size: got {}, expected {}\".format(\n",
    "                    input.size(1), self.input_size))                     \n",
    "\n",
    "class CLSTM_layers(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=3, name='CLSTM-Layers'):\n",
    "        super(CLSTM_layers, self).__init__()\n",
    "            \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        cell_0 = [CLSTM_cell(input_size, hidden_size)]\n",
    "        self.cells = nn.ModuleList(cell_0 + [CLSTM_cell(hidden_size, hidden_size) for i in range(1,num_layers)])\n",
    "        \n",
    "    def getShapedTensor(self, input, repeat_input=False):\n",
    "        if repeat_input:\n",
    "            return torch.zeros(input.size(0), self.hidden_size, input.size(2), input.size(3), dtype=input.dtype, device=input.device)\n",
    "        else:\n",
    "            return torch.zeros(input.size(0), self.hidden_size, input.size(3), input.size(4), dtype=input.dtype, device=input.device)\n",
    "\n",
    "    def forward(self, input, H=None, C=None, return_sequence=False, repeat_input=False, output_sequence_length=8):\n",
    "        # if return sequence: return all h's, \n",
    "        # else: returns last H and C\n",
    "            \n",
    "        if repeat_input:\n",
    "            Hs = [self.getShapedTensor(input, True) for _ in range(output_sequence_length)]  \n",
    "        else:\n",
    "            Hs = [self.getShapedTensor(input) for _ in range(input.size(1))]  \n",
    "        \n",
    "        if not isinstance(H, type(None)):\n",
    "            Hs[0] = H\n",
    "        if isinstance(C, type(None)):\n",
    "            C = self.getShapedTensor(input, repeat_input)\n",
    "                \n",
    "        if repeat_input: \n",
    "            for t in range(output_sequence_length):\n",
    "                H, C = self.cells[0](input, H=H, C=C)\n",
    "                Hs[t] = H\n",
    "                \n",
    "            for l in range(1, len(self.cells)):  \n",
    "                for t in range(output_sequence_length):\n",
    "                    if t==0:\n",
    "                        C = self.getShapedTensor(input, repeat_input)\n",
    "                    H, C = self.cells[l](Hs[t], H=H, C=C)\n",
    "                    Hs[t] = H\n",
    "        else:\n",
    "            for t in range(input.size(1)): # numer of time-steps\n",
    "                H, C = self.cells[0](input[:,t], H=H, C=C)\n",
    "                Hs[t] = H\n",
    "                \n",
    "            for l in range(1, len(self.cells)):  \n",
    "                for t in range(input.size(1)):\n",
    "                    if t==0:\n",
    "                        C = self.getShapedTensor(input, repeat_input)\n",
    "                    H, C = self.cells[l](Hs[t], H=H, C=C)\n",
    "                    Hs[t] = H  \n",
    "        \n",
    "        if return_sequence:\n",
    "            return torch.stack(Hs).transpose(0,1) # [b,t,hd,:,:]\n",
    "        #print(Hs[-1].shape)\n",
    "        return Hs[-1], C# [b,hd,:,:], [b,hd,:,:], [b,hd,:,:]\n",
    "\n",
    "class CLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None, directional=1, name='CLSTM'):\n",
    "        super(CLSTM, self).__init__()\n",
    "        \n",
    "        self.id = 'CLSTM'\n",
    "        \n",
    "        clstm_hidden_size=hidden_size\n",
    "        \n",
    "        if output_size==None:\n",
    "            output_size = input_size\n",
    "\n",
    "        self.encoder = TimeDistributed(Encoder(input_size, hidden_size, output_size=hidden_size))\n",
    "        self.decoder = TimeDistributed(Decoder(clstm_hidden_size, hidden_size, output_size=output_size))\n",
    "        \n",
    "        self.encoder_clstm = CLSTM_layers(hidden_size,clstm_hidden_size, num_layers=3)      \n",
    "        self.decoder_clstm = CLSTM_layers(clstm_hidden_size, clstm_hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, input, max_depth=10):\n",
    "        input = self.encoder(input)\n",
    "        H, C = self.encoder_clstm(input.flip(1), return_sequence=False)   \n",
    "        input = self.decoder_clstm(H, H=H, C=C, return_sequence=True, repeat_input=True, output_sequence_length=max_depth)\n",
    "        input = self.decoder(input)\n",
    "        return input.transpose(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d213b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "\n",
    "class HeartStaticDataset(Dataset):\n",
    "    def __init__(self, config, sim_name='Scroll1', kind='V', mode='projection'):\n",
    "        self.config = config \n",
    "        \n",
    "        def atoi(text):\n",
    "            return int(text) if text.isdigit() else text\n",
    "\n",
    "        def natural_keys(text):\n",
    "            return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "        \n",
    "        if config.kind=='V':\n",
    "            names = 'V_snap*'\n",
    "        else:\n",
    "            names = 'C_snap*'\n",
    "            \n",
    "        self.mode = mode\n",
    "            \n",
    "        basename = os.path.join(config.data_folder, names)\n",
    "        self.files = glob.glob(basename)\n",
    "        self.files.sort(key=natural_keys)\n",
    "        \n",
    "        self.surface = np.fromfile(self.config.surface_file, dtype=np.int32)\n",
    "        #self.surface_inds = self.List2Vec(surface)\n",
    "        \n",
    "        self.outer_surface = np.load(self.config.outer_surface_file)\n",
    "        self.outer_surface_inds = self.List2Vec(self.outer_surface)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return 300\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # mode can be: 'load_file', 'surface', 'projection'\n",
    "        #return np.load(self.files[idx])\n",
    "        \n",
    "        # 1: Load file\n",
    "        data = np.fromfile(self.files[idx], dtype=np.double)\n",
    "        if self.config.mode=='load_file':\n",
    "            return data\n",
    "        \n",
    "        # 2: Extract points to surface inds\n",
    "        dense_pc = self.List2Vec(data*self.Vec2List(self.outer_surface_inds), return_values=True)\n",
    "        if self.config.mode=='surface':\n",
    "            return dense_pc\n",
    "        \n",
    "        # 3: Project to\n",
    "        soff = np.mean(dense_pc[:,:3], axis=0)\n",
    "        dense_pc_projected = self.get_spherical_projection(dense_pc[:,:3], *soff, 300)\n",
    "            \n",
    "        if self.config.mode=='projection':\n",
    "            return dense_pc_projected\n",
    "\n",
    "        return dense_pc\n",
    "    \n",
    "    def List2Vec(self, lst, return_values=False):\n",
    "        vecs = np.reshape(lst, self.config.shape)\n",
    "        pos = np.array(np.where(vecs!=0)).T.astype(np.int16)\n",
    "\n",
    "        if return_values==False:\n",
    "            return pos\n",
    "\n",
    "        values = np.array([vecs[pos[:,0], pos[:,1],pos[:,2]]]).T\n",
    "        return np.concatenate([pos, values], axis=1)\n",
    "\n",
    "    def Vec2List(self, vecs):\n",
    "        cube = np.zeros(self.config.shape)\n",
    "        cube[vecs[:,0], vecs[:,1], vecs[:,2]] = 1\n",
    "        lst = np.reshape(cube, -1)\n",
    "        return lst\n",
    "    \n",
    "    def get_spherical_projection(self, coords,x0,y0,z0,r1):\n",
    "        x2 = coords[:,0]\n",
    "        y2 = coords[:,1]\n",
    "        z2 = coords[:,2]\n",
    "        x0 = x0 * np.ones(x2.size)\n",
    "        y0 = y0 * np.ones(y2.size)\n",
    "        z0 = z0 * np.ones(z2.size)\n",
    "        r1 = r1 * np.ones(x2.size)\n",
    "        r2 = np.power(np.square(x2-x0)+np.square(y2-y0)+np.square(z2-z0),0.5)\n",
    "        x_new = x0 + (r1/r2) * (x2-x0)\n",
    "        y_new = y0 + (r1/r2) * (y2-y0)\n",
    "        z_new = z0 + (r1/r2) * (z2-z0)\n",
    "        return np.array([x_new,y_new,z_new]).T\n",
    "\n",
    "class HeartDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = BarkleyDataset(self.config.dataset_dir, \n",
    "                                 time_steps=self.config.time_step, \n",
    "                                 depth=self.config.depth)\n",
    "        print(dataset)\n",
    "        \n",
    "        n_train = int(len(dataset)*0.95+0.5)\n",
    "        n_val = int(len(dataset)*0.05+0.5)\n",
    "        \n",
    "        self.train_dataset, self.val_dataset = random_split(dataset, [n_train, n_val])   \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.train_dataset, batch_size=self.config.batch_size, num_workers=4, shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val_dataset, batch_size=self.config.batch_size, num_workers=4, shuffle=False)\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.val_dataset, batch_size=self.config.batch_size, num_workers=4, shuffle=False)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7effe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
